{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: \n",
    "\n",
    "This notebook is a bit overly-complicated but the bulk of it all just has to do with data organization. Since this project is winding down I'm not going to clean this up to shorten the code substantially but rather let this here for posterity. All these metrics *should* have been pre-computed so if you have access to the results data it will be unnecessary to run the code in this notebook unless we have new models what we want to assess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring structure models with `QMEANDisCo`\n",
    "\n",
    "**This code submits jobs and accesses QMEANDisCO software using the programatic API rather than downloading and running it on my own computer. At a certain point, it probably would be best to download/install the software.**\n",
    "\n",
    "The server is located here: https://swissmodel.expasy.org/qmean/\n",
    "\n",
    "And a link to the paper is here: https://doi.org/10.1093/bioinformatics/btz828\n",
    "\n",
    "In my experience, a submission to this server takes ~5 minutes to complete so I space out individual requests so as not to overload their servers or get flagged. In order to submit too many jobs or to perform this step too frequently, the first thing that I do is check whether the relevant files already exist on my computer (assuming a very particular directory structure) and if so I skip them and only submit jobs for new proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries to handle internet requests and to manage the file system\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "\n",
    "qmean_url = 'https://swissmodel.expasy.org/qmean/submit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First working through the (initial) IF2 and EFTU structures from `trRosetta`\n",
    "\n",
    "**Basically, I first cycle through and send a lot of requests to the `qmeandisco` server. I compile all the results into a dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This is where I want to put results\n",
    "save_dir = '../Results/QMEAN/trRosetta/'\n",
    "assert os.path.exists(save_dir)\n",
    "\n",
    "###Send requests (if I don't already have them)\n",
    "response_dict = {}\n",
    "for base_dir in glob.glob('../Results/trRosetta/EFTU_*') + glob.glob('../Results/trRosetta/IF2_*'):\n",
    "\n",
    "    ##############################################################################################\n",
    "    ###Note: need to manually cycle through model1, model2, ... model 5 below to finish all models\n",
    "    my_file_loc = base_dir + '/model1.pdb'\n",
    "    ##############################################################################################\n",
    "    \n",
    "    ###This is where I'm going to save the new QMEANDisCo file\n",
    "    f_out = my_file_loc.split('/')[-2] + '_' + my_file_loc.split('/')[-1]\n",
    "    f_out = f_out.split('.')[0]\n",
    "    print(base_dir, f_out)\n",
    "    ###This code says to start the loop over if this file already exists\n",
    "    if os.path.exists('{}{}.json'.format(save_dir, f_out)):\n",
    "        print('Already finished this one')\n",
    "        continue\n",
    "    \n",
    "    ###Send the actual request\n",
    "    response = requests.post(url=qmean_url,\n",
    "                         data={'email': 'adam.hockenberry@utexas.edu'},\n",
    "                         files={'structure': open(my_file_loc,'r')})\n",
    "    ###Store the response for now\n",
    "    response_dict[my_file_loc] = response\n",
    "    ###And take a little nap before moving on\n",
    "    time.sleep(360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now to process / download the results from that dictionary from all the initial queries that have (hopefully) completed their processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Iterate through items in the dictionary\n",
    "for key, value in response_dict.items():\n",
    "    print(key, value.status_code)\n",
    "    \n",
    "    ###Determine where I'm saving the file to (again)\n",
    "    f_out = key.split('/')[-2] + '_' + key.split('/')[-1]\n",
    "    f_out = f_out.split('.')[0]\n",
    "    print(f_out)\n",
    "    \n",
    "    ###Actually save the '.json' file\n",
    "    try:\n",
    "        current_status = requests.get(value.json()[\"results_json\"])\n",
    "        results = current_status.json()\n",
    "        with open('{}{}.json'.format(save_dir, f_out), 'w') as outfile:\n",
    "            json.dump(results, outfile)\n",
    "        ###Take a shorter nap\n",
    "        time.sleep(60)\n",
    "    except:\n",
    "        print('Did not work, manually fix/investigate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now going through the (initial) IF2 and EFTU structures from `I-TASSER`\n",
    "\n",
    "This code is basically identical to the above few code cells so I'm not annotating as much here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../Results/QMEAN/ITASSER/'\n",
    "assert os.path.exists(save_dir)\n",
    "\n",
    "response_dict = {}\n",
    "for base_dir in glob.glob('../Results/ITASSER/IF2_*')+glob.glob('../Results/ITASSER/EFTU_*')[:]:\n",
    "    ###Remember to manually change the model numbers to run on both model1 and model2\n",
    "    \n",
    "    ##############################################################################################\n",
    "    my_file_loc = base_dir + '/model2.pdb' \n",
    "    ##############################################################################################\n",
    "\n",
    "\n",
    "    f_out = my_file_loc.split('/')[-2] + '_' + my_file_loc.split('/')[-1]\n",
    "    f_out = f_out.split('.')[0]\n",
    "    print(base_dir, f_out)\n",
    "    if os.path.exists('{}{}.json'.format(save_dir, f_out)):\n",
    "        print('Already finished this one')\n",
    "        continue\n",
    "    response = requests.post(url=qmean_url,\n",
    "                         data={'email': 'adam.hockenberry@utexas.edu'},\n",
    "                         files={'structure': open(my_file_loc,'r')})\n",
    "    response_dict[my_file_loc] = response\n",
    "    time.sleep(240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Process request outputs and save\n",
    "for key, value in response_dict.items():\n",
    "    print(key, value.status_code)\n",
    "    f_out = key.split('/')[-2] + '_' + key.split('/')[-1]\n",
    "    f_out = f_out.split('.')[0]\n",
    "    print(f_out)\n",
    "    try:\n",
    "        current_status = requests.get(value.json()[\"results_json\"])\n",
    "        results = current_status.json()\n",
    "        with open('{}{}.json'.format(save_dir, f_out), 'w') as outfile:\n",
    "            json.dump(results, outfile)\n",
    "        time.sleep(60)\n",
    "    except:\n",
    "        print('Did not work, manually fix/investigate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now running analyses on the \"clean\" template files from `PDB`\n",
    "\n",
    "Again the code is pretty much identical to the above sections so not annotating much here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../Results/QMEAN/empirical/'\n",
    "assert os.path.exists(save_dir)\n",
    "\n",
    "response_dict = {}\n",
    "for my_file_loc in glob.glob('../Data/Structures/Template_structures/*.clean.pdb')[:]:\n",
    "    f_out = 'Templates' + '_' + my_file_loc.split('/')[-1]\n",
    "    f_out = f_out.split('.')[0]\n",
    "    print(f_out)\n",
    "    print(base_dir, f_out)\n",
    "    if os.path.exists('{}{}.json'.format(save_dir, f_out)):\n",
    "        print('Already finished this one')\n",
    "        continue\n",
    "    response = requests.post(url=qmean_url,\n",
    "                         data={'email': 'adam.hockenberry@utexas.edu'},\n",
    "                         files={'structure': open(my_file_loc,'r')})\n",
    "    response_dict[my_file_loc] = response\n",
    "    time.sleep(240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Process request outputs and save\n",
    "for key, value in response_dict.items():\n",
    "    print(key, value.status_code)\n",
    "    f_out = key.split('/')[-2] + '_' + key.split('/')[-1]\n",
    "    f_out = f_out.split('.')[0]\n",
    "    print(f_out)\n",
    "    try:\n",
    "        current_status = requests.get(value.json()[\"results_json\"])\n",
    "        results = current_status.json()\n",
    "        with open('{}{}.json'.format(save_dir, f_out), 'w') as outfile:\n",
    "            json.dump(results, outfile)\n",
    "        time.sleep(60)\n",
    "    except:\n",
    "        print('Did not work, manually fix/investigate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, the `modeller` models\n",
    "\n",
    "**To keep things consistent with some of the programs I'm going to re-name the files here as well when I write them so that I have model1.pdb, model2.pdb, *etc.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = '../Results/modeller/'\n",
    "for base_dir in glob.glob('../Data/Structures/Anc_Structures_v2/IF2_*')[:]:\n",
    "    if 'IF2_Anc559' in base_dir:\n",
    "        continue\n",
    "    if '1zo1' in base_dir:\n",
    "        continue\n",
    "    try:\n",
    "        log_file = base_dir + '/model-single.log'\n",
    "        with open(log_file, 'r') as infile:\n",
    "            tempy = infile.readlines()[-6:]\n",
    "    except FileNotFoundError:\n",
    "        log_file = base_dir + '/model_mult.log'\n",
    "        with open(log_file, 'r') as infile:\n",
    "            tempy = infile.readlines()[-6:]\n",
    "    df = pd.read_csv(StringIO(''.join(tempy)), delim_whitespace=True, header=None)\n",
    "    if 'model-single' in log_file:\n",
    "        df = df.sort_values(2)\n",
    "    elif 'model_mult' in log_file:\n",
    "        df = df.sort_values(1)\n",
    "    else:\n",
    "        print('MAJOR ERROR HERE')\n",
    "        break\n",
    "    assert df.shape[0] == 5\n",
    "    for i, index in enumerate(list(df.index)):\n",
    "        old_file_loc = base_dir + '/' + df.loc[index][0]\n",
    "        new_file_loc = base_dir + '/' + 'model{}.pdb'.format(i+1)\n",
    "        print(old_file_loc, new_file_loc)\n",
    "        ##Make new copies within the original Data folder\n",
    "        shutil.copy(old_file_loc, new_file_loc)\n",
    "        ##And copy over to the Results folder for consistency\n",
    "        newer_file_loc = new_file_loc.replace('/Data/Structures/Anc_Structures_v2/', '/Results/modeller/')\n",
    "        if not os.path.exists(os.path.dirname(newer_file_loc)):\n",
    "            os.makedirs(os.path.dirname(newer_file_loc), exist_ok=True)\n",
    "        shutil.copy(new_file_loc, newer_file_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now go through that same old process of sending away queries and holding the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../Results/QMEAN/modeller/'\n",
    "assert os.path.exists(save_dir)\n",
    "\n",
    "response_dict = {}\n",
    "for base_dir in glob.glob('../Results/modeller/*')[:]:\n",
    "    \n",
    "    ##############################################################################################\n",
    "    my_file_loc = base_dir + '/model5.pdb' ###Manually specify model numbers\n",
    "    ##############################################################################################\n",
    "\n",
    "    ###If you know there are particular files you want to ignore you can use this type of an approach\n",
    "#     if '/IF2_Anc702_3jcj_1efc/' not in my_file_loc and '/IF2_Anc719_3jcj_1efc/' not in my_file_loc:\n",
    "#         continue\n",
    "    \n",
    "    f_out = my_file_loc.split('/')[-2] + '_' + my_file_loc.split('/')[-1]\n",
    "    f_out = f_out.split('.')[0]\n",
    "    print(base_dir, f_out)\n",
    "    if os.path.exists('{}{}.json'.format(save_dir, f_out)):\n",
    "        print('Already finished this one')\n",
    "        continue\n",
    "    response = requests.post(url=qmean_url,\n",
    "                         data={'email': 'adam.hockenberry@utexas.edu'},\n",
    "                         files={'structure': open(my_file_loc,'r')})\n",
    "    response_dict[my_file_loc] = response\n",
    "    time.sleep(360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And finally, downloading them into their proper location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Process request outputs and save\n",
    "for key, value in response_dict.items():\n",
    "    print(key, value.status_code)\n",
    "    f_out = key.split('/')[-2] + '_' + key.split('/')[-1]\n",
    "    f_out = f_out.split('.')[0]\n",
    "    print(f_out)\n",
    "    try:\n",
    "        current_status = requests.get(value.json()[\"results_json\"])\n",
    "        results = current_status.json()\n",
    "        with open('{}{}.json'.format(save_dir, f_out), 'w') as outfile:\n",
    "            json.dump(results, outfile)\n",
    "        time.sleep(60)\n",
    "    except:\n",
    "        print('Did not work, manually fix/investigate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble structure quality data from *all* sources into a dataframe/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_molecule_list = []\n",
    "molecule_id_list = []\n",
    "model_number_list = []\n",
    "template_id_list = []\n",
    "qmean_score_list = []\n",
    "source_list = []\n",
    "\n",
    "for results_dir in glob.glob('../Results/QMEAN/*'):\n",
    "    print(results_dir)\n",
    "    source = results_dir.split('/')[-1]\n",
    "    method = results_dir.split('/')[-1]\n",
    "    for json_loc in glob.glob(results_dir + '/*.json'):\n",
    "        print(json_loc)\n",
    "        structure_name = json_loc.split('/')[-1]\n",
    "        if source == 'empirical':\n",
    "            molecule_id = structure_name.split('_')[1].split('.json')[0]\n",
    "            if molecule_id in ['1zo1', '3jcjF']:\n",
    "                base_molecule = 'IF2'\n",
    "            elif molecule_id in ['1efc', '6gfu']:\n",
    "                base_molecule = 'EFTU'\n",
    "            else:\n",
    "                raise Exception('Major error in if statement')\n",
    "            model_number = ''\n",
    "            template_id = ''\n",
    "        else:\n",
    "            base_molecule = structure_name.split('_')[0]\n",
    "            molecule_id = structure_name.split('_')[1]\n",
    "            if method == 'modeller':\n",
    "                if len(structure_name.split('_')) == 3:\n",
    "                    if base_molecule == 'IF2':\n",
    "                        template_id = '1zo1'\n",
    "                    elif base_molecule == 'EFTU':\n",
    "                        template_id = '1efc'\n",
    "                    else:\n",
    "                        raise Exception('Major error in if statement number 2')\n",
    "                    model_number = structure_name.split('_')[2].split('.')[0]\n",
    "                    \n",
    "                elif len(structure_name.split('_')) == 4:\n",
    "                    template_id = structure_name.split('_')[2]\n",
    "                    model_number = structure_name.split('_')[3].split('.')[0]\n",
    "                    \n",
    "                elif len(structure_name.split('_')) == 5:\n",
    "                    template_id = '_'.join([structure_name.split('_')[2], structure_name.split('_')[3]])\n",
    "                    model_number = structure_name.split('_')[4].split('.')[0]\n",
    "                else:\n",
    "                    raise Exception('Major error in if statement number 3')\n",
    "            else:\n",
    "                template_id = ''\n",
    "                model_number = structure_name.split('_')[2].split('.')[0]\n",
    "\n",
    "            print('####', base_molecule, molecule_id, model_number, template_id)\n",
    "            \n",
    "        with open(json_loc, 'r') as infile:\n",
    "            results = json.load(infile)\n",
    "        my_metric = results['models']['model_001']['scores']['global_scores']['avg_local_score']\n",
    "\n",
    "        base_molecule_list.append(base_molecule)\n",
    "        molecule_id_list.append(molecule_id)\n",
    "        template_id_list.append(template_id)\n",
    "        model_number_list.append(model_number)\n",
    "        source_list.append(source)\n",
    "        qmean_score_list.append(my_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(base_molecule_list, molecule_id_list, template_id_list, model_number_list, source_list, qmean_score_list))\n",
    "df.columns = ['protein', 'variant', 'template', 'model_number', 'source', 'qmeandisco_score']\n",
    "df = df.sort_values(['source', 'protein', 'variant', 'model_number', 'qmeandisco_score'])\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['source']=='modeller']['template'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Results/QMEAN/full_results.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select only the top `QMEANDisCo` model and save as a separate `.tsv` file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = df.loc[df.groupby(['protein', 'variant', 'source'], sort=False)['qmeandisco_score'].idxmax()] \n",
    "best_df = best_df.sort_values(['protein', 'variant', 'model_number', 'source', 'qmeandisco_score'])\n",
    "best_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df.to_csv('../Results/QMEAN/best_results.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, comparing different modeller templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###IF2 plots\n",
    "protein = 'IF2'\n",
    "model_labels_1 = ['Anc520',\n",
    "               'Anc536',\n",
    "               'Anc550',\n",
    "               'Anc558',\n",
    "               'Anc622',\n",
    "               'Anc670',\n",
    "               'Anc702',\n",
    "               'Anc719',\n",
    "               'Anc743',\n",
    "               'Anc750',\n",
    "               'Anc754',\n",
    "               'Anc788',\n",
    "                'Anc789']\n",
    "model_labels_3 = ['1zo1', '3jcjF']\n",
    "\n",
    "all_model_labels = model_labels_1 + model_labels_3\n",
    "x_vals = list(range(len(all_model_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Best plot\n",
    "fig, ax = plt.subplots(figsize=(5,2))\n",
    "x_offset=-0.1\n",
    "method = 'modeller'\n",
    "templates = ['1zo1', '3jcj', '3jcj_1efc']\n",
    "for i, template in enumerate(templates):\n",
    "    print(template)\n",
    "    temp_df = df[(df['source']==method)&(df['protein']==protein)]\n",
    "    temp_df = temp_df[temp_df['template']==template]\n",
    "    print(temp_df.shape)\n",
    "    y_vals_1 = []\n",
    "    y_vals_2 = []\n",
    "    for label in model_labels_1:\n",
    "        proposed_df = temp_df[temp_df['variant']==label]\n",
    "        proposed_df = proposed_df.sort_values('qmeandisco_score', ascending=False)\n",
    "        if proposed_df.shape[0] >= 1:\n",
    "            y_vals_1.append(proposed_df.iloc[0]['qmeandisco_score'])\n",
    "        else:\n",
    "            y_vals_1.append(np.nan)\n",
    "    \n",
    "    ax.plot(np.array(x_vals[:len(model_labels_1)])+x_offset,\n",
    "            y_vals_1,\n",
    "            label='Template={}'.format(template),\n",
    "            color=colors[i],\n",
    "            marker='s')\n",
    "    x_offset += 0.1\n",
    "\n",
    "\n",
    "temp_df = best_df[(best_df['source']=='empirical')&(best_df['protein']==protein)]\n",
    "y_vals_3 = []\n",
    "for label in model_labels_3:\n",
    "    proposed_df = temp_df[temp_df['variant']==label]\n",
    "    if proposed_df.shape[0] == 1:\n",
    "        y_vals_3.append(proposed_df.iloc[0]['qmeandisco_score']) \n",
    "    else:\n",
    "        y_vals_3.append(np.nan)\n",
    "ax.plot(x_vals[len(model_labels_1):],\n",
    "        y_vals_3,\n",
    "        color=colors[i+1],\n",
    "        linestyle='',\n",
    "        marker='s',\n",
    "        label='Empirical')\n",
    "    \n",
    "ax.set_ylim(0, 1)\n",
    "ax.axvline(len(x_vals)-len(model_labels_3)-0.5, c='k')\n",
    "ax.set_xticks(x_vals)\n",
    "ax.set_xticklabels(all_model_labels, rotation=90);\n",
    "ax.set_ylabel('QMEANDisCo (max)')\n",
    "# ax.legend(ncol=2, loc='best')\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [0, 1, 2, 3]\n",
    "ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, plotting only the best model for all cases with multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###IF2 plots\n",
    "protein = 'IF2'\n",
    "model_labels_1 = ['Anc520',\n",
    "               'Anc536',\n",
    "               'Anc550',\n",
    "               'Anc558',\n",
    "               'Anc622',\n",
    "               'Anc670',\n",
    "               'Anc702',\n",
    "               'Anc719',\n",
    "               'Anc743',\n",
    "               'Anc750',\n",
    "               'Anc754',\n",
    "               'Anc788']\n",
    "model_labels_2 = ['1zo1', '3jcjF']\n",
    "model_labels_3 = ['1zo1', '3jcjF']\n",
    "\n",
    "\n",
    "# ##EFTU plots\n",
    "# protein = 'EFTU'\n",
    "# model_labels_1 = ['Anc168',\n",
    "#                'Anc262']\n",
    "# model_labels_2 = ['1efc']\n",
    "# model_labels_3 = ['1efc', '6gfu']\n",
    "\n",
    "\n",
    "all_model_labels = model_labels_1 + model_labels_2 + model_labels_3\n",
    "x_vals = list(range(len(all_model_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Best plot\n",
    "fig, ax = plt.subplots(figsize=(5,2))\n",
    "x_offset=-0.1\n",
    "methods = ['trRosetta', 'ITASSER', 'modeller']\n",
    "for i, method in enumerate(methods):\n",
    "    temp_df = best_df[(best_df['source']==method)&(best_df['protein']==protein)]\n",
    "    y_vals_1 = []\n",
    "    y_vals_2 = []\n",
    "    for label in model_labels_1:\n",
    "        proposed_df = temp_df[temp_df['variant']==label]\n",
    "        if proposed_df.shape[0] == 1:\n",
    "            y_vals_1.append(proposed_df.iloc[0]['qmeandisco_score'])\n",
    "        else:\n",
    "            y_vals_1.append(np.nan)\n",
    "    for label in model_labels_2:\n",
    "        proposed_df = temp_df[temp_df['variant']==label]\n",
    "        if proposed_df.shape[0] == 1:\n",
    "            y_vals_2.append(proposed_df.iloc[0]['qmeandisco_score']) \n",
    "        else:\n",
    "            y_vals_2.append(np.nan)\n",
    "    \n",
    "    ax.plot(np.array(x_vals[:len(model_labels_1)])+x_offset,\n",
    "            y_vals_1,\n",
    "            label=method,\n",
    "            color=colors[i],\n",
    "            marker='s')\n",
    "    \n",
    "    ax.plot(np.array(x_vals[len(model_labels_1):len(model_labels_1)+len(model_labels_2)])+x_offset,\n",
    "            y_vals_2,\n",
    "            color=colors[i],\n",
    "            linestyle='',\n",
    "            marker='s')\n",
    "    x_offset += 0.1\n",
    "\n",
    "\n",
    "temp_df = best_df[(best_df['source']=='empirical')&(best_df['protein']==protein)]\n",
    "y_vals_3 = []\n",
    "for label in model_labels_3:\n",
    "    proposed_df = temp_df[temp_df['variant']==label]\n",
    "    if proposed_df.shape[0] == 1:\n",
    "        y_vals_3.append(proposed_df.iloc[0]['qmeandisco_score']) \n",
    "    else:\n",
    "        y_vals_3.append(np.nan)\n",
    "ax.plot(x_vals[len(model_labels_1)+len(model_labels_2):],\n",
    "        y_vals_3,\n",
    "        color=colors[i+1],\n",
    "        linestyle='',\n",
    "        marker='s',\n",
    "        label='Empirical')\n",
    "    \n",
    "ax.set_ylim(0, 1)\n",
    "ax.axvline(len(x_vals)-len(model_labels_3)-0.5, c='k')\n",
    "ax.axvline(len(x_vals)-len(model_labels_2)-len(model_labels_3)-0.5, c='k')\n",
    "ax.set_xticks(x_vals)\n",
    "ax.set_xticklabels(all_model_labels, rotation=90);\n",
    "ax.set_ylabel('QMEANDisCo (max)')\n",
    "# ax.legend(ncol=2, loc='best')\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [0, 1, 2, 3]\n",
    "ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, plotting means plus standard deviations (when possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Best plot\n",
    "fig, ax = plt.subplots(figsize=(5,2))\n",
    "\n",
    "methods = ['trRosetta', 'ITASSER', 'modeller']\n",
    "x_offset=-0.1\n",
    "for i, method in enumerate(methods):\n",
    "    temp_df = df[(df['source']==method)&(df['protein']==protein)]\n",
    "    y_vals_1 = []\n",
    "    y_errs_1 = []\n",
    "    y_vals_2 = []\n",
    "    y_errs_2 = []\n",
    "    for label in model_labels_1:\n",
    "        proposed_df = temp_df[temp_df['variant']==label]\n",
    "        if proposed_df.shape[0] > 0:\n",
    "            y_vals_1.append(proposed_df['qmeandisco_score'].mean())\n",
    "            y_errs_1.append(proposed_df['qmeandisco_score'].std())\n",
    "        else:\n",
    "            y_vals_1.append(np.nan)\n",
    "            y_errs_1.append(np.nan)\n",
    "    for label in model_labels_2:\n",
    "        proposed_df = temp_df[temp_df['variant']==label]\n",
    "        if proposed_df.shape[0] > 0:\n",
    "            y_vals_2.append(proposed_df['qmeandisco_score'].mean())\n",
    "            y_errs_2.append(proposed_df['qmeandisco_score'].std())\n",
    "        else:\n",
    "            y_vals_2.append(np.nan)\n",
    "            y_errs_2.append(np.nan)\n",
    "    \n",
    "    ax.errorbar(np.array(x_vals[:len(model_labels_1)])+x_offset,\n",
    "            y_vals_1,\n",
    "            yerr=y_errs_1,\n",
    "            label=method,\n",
    "            color=colors[i],\n",
    "            marker='s')\n",
    "    ax.errorbar(np.array(x_vals[len(model_labels_1):len(model_labels_1)+len(model_labels_2)])+x_offset,\n",
    "            y_vals_2,\n",
    "            yerr=y_errs_2,\n",
    "            color=colors[i],\n",
    "            linestyle='',\n",
    "            marker='s')\n",
    "    x_offset += 0.1\n",
    "temp_df = best_df[(best_df['source']=='empirical')&(best_df['protein']==protein)]\n",
    "y_vals_3 = []\n",
    "for label in model_labels_3:\n",
    "    proposed_df = temp_df[temp_df['variant']==label]\n",
    "    if proposed_df.shape[0] == 1:\n",
    "        y_vals_3.append(proposed_df.iloc[0]['qmeandisco_score']) \n",
    "    else:\n",
    "        y_vals_3.append(np.nan)\n",
    "ax.plot(x_vals[len(model_labels_1)+len(model_labels_2):],\n",
    "        y_vals_3,\n",
    "        color=colors[i+1],\n",
    "        linestyle='',\n",
    "        marker='s',\n",
    "        label='Empirical')\n",
    "    \n",
    "ax.set_ylim(0, 1)\n",
    "ax.axvline(len(x_vals)-len(model_labels_3)-0.5, c='k')\n",
    "ax.axvline(len(x_vals)-len(model_labels_2)-len(model_labels_3)-0.5, c='k')\n",
    "ax.set_xticks(x_vals)\n",
    "ax.set_xticklabels(all_model_labels, rotation=90);\n",
    "ax.set_ylabel('QMEANDisCo (mean)')\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [1, 2, 3, 0]\n",
    "ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "300px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
